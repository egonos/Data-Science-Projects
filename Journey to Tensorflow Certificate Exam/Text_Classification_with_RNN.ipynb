{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym5hsh1yu27p",
        "outputId": "f4164362-b1ff-4cd5-863f-360219a05711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 250), (25000, 250))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#determine the parameters\n",
        "VOCAB_SIZE = 10000\n",
        "MAXLEN = 250\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "#already tokenized\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=VOCAB_SIZE)\n",
        "\n",
        "#to put the tokens we need to have constant dimensions\n",
        "train_data = pad_sequences(train_data, maxlen=MAXLEN)\n",
        "test_data = pad_sequences(test_data, maxlen=MAXLEN)\n",
        "\n",
        "train_data.shape, test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(VOCAB_SIZE, 32, input_length=MAXLEN),  # Embedding layer\n",
        "    LSTM(32),  # LSTM layer with 32 units\n",
        "    Dense(1, activation='sigmoid')  # Dense layer for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1qmwLXy0u6yV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data, train_labels, epochs=5, batch_size=64, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM9vmh-JvFNM",
        "outputId": "029f2bdb-61d7-485f-8ddf-aa0052b066d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - 47s 142ms/step - loss: 0.4424 - accuracy: 0.7821 - val_loss: 0.3729 - val_accuracy: 0.8390\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 44s 139ms/step - loss: 0.2408 - accuracy: 0.9090 - val_loss: 0.3012 - val_accuracy: 0.8774\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 43s 137ms/step - loss: 0.1721 - accuracy: 0.9392 - val_loss: 0.3781 - val_accuracy: 0.8644\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 43s 138ms/step - loss: 0.1444 - accuracy: 0.9491 - val_loss: 0.3446 - val_accuracy: 0.8606\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 45s 143ms/step - loss: 0.1133 - accuracy: 0.9616 - val_loss: 0.4151 - val_accuracy: 0.8744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viable options:\n",
        "```\n",
        "LSTM(return sequences = True)\n",
        "GlobalAveragePooling1D()\n",
        "Dense...\n",
        "\n",
        "LSTM(return_sequences = False)\n",
        "Dense...\n",
        "```"
      ],
      "metadata": {
        "id": "pSIxq5DJv6vx"
      }
    }
  ]
}