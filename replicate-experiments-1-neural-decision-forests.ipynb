{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:46:09.703835Z","iopub.execute_input":"2022-07-12T09:46:09.704420Z","iopub.status.idle":"2022-07-12T09:46:22.061196Z","shell.execute_reply.started":"2022-07-12T09:46:09.704306Z","shell.execute_reply":"2022-07-12T09:46:22.059859Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Goal of This Notebook\n\nThe goal of this notebook is replicating one of the experiments in [[1]](https://arxiv.org/pdf/1806.06988.pdf) and verifying the results. This notebook was prepared mainly for learning purposes.\n\n# Brief Introduction on Deep Neural Decision Trees\n\nTree algorithms are really useful when it comes to tabular data. They yield successful results (I'm sure you recognized this from the winner models of many competitions). Besides that, they are interetable which is really important for almost all the real life examples.\n\nThe Neural Networks particulary handy when the data is perceptual. Signal, semantic, picture and audio data can be processed via NN.\n\nCurrently, researchers try to combine two and create better ones. Some examples can be,\n\n* **Tensorflow Decision Forest Applications:** Tensorflow supports Ensemble Trees and Gradient Boosted Trees. One can combine deep learning architechtures with these and get sweet results. You can look my previous [work](https://www.kaggle.com/code/egemenuurdalg/modeling-tree-algorithms-for-nlp-tasks) where I used different tree algorithms with different preprocessing layers for NLP classification task. I also compared the results with the performance of sequential cells and BERT.\n\n* **Composed Decision Forest and Neural Network:** The aim is combine multiple decision forests and neural nets to improve predictive performance[[2]](https://www.tensorflow.org/decision_forests/tutorials/model_composition_colab).\n\n* **Deep Neural Decision Trees:** The goal is constructing a tree which splits based on the results of multilayer perceptrons. While Neural Decision Tree is designed mainly for interpretability, the ensemble of Neural Decision Trees can be used for higer prediction performance.  \n\n\n# Methodology\n\n* Since the number of predictors is less than 12, I used Neural Decision Trees instead of Neural Decision Forests. (There is an example in [keras website](https://keras.io/examples/structured_data/deep_neural_decision_forests/) if you are curious about that.\n\n* I used Titanic Dataset to train Neural Nets, Decision Tree Classifier and Neural Decision Tree algorithms.\n\n* The categorical features have just couple of unique variables so I used [One Hot Encoding](https://en.wikipedia.org/wiki/One-hot) to preprocess them.\n\n* I didn't used any normalization agent for neural nets because it did not improve the predictive performance.\n\n* Since the goal is binary classification, I used [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) for the outputs of Deep Neural Trees.\n\n* In paper there is no specification regarding tree depth and number of epochs. Based on the predictive performance I find the parameters by trial & error and early stopping.\n\n* I arranged the other parameters based on the paper.\n\n# Results\n\nExcept decision tree the results in this notebook came similar with the ones in the paper. \n           \n* DNDT (Paper): 80.4\n* DT (Paper): 79.0\n* NN (Paper): 76.9\n* DNDT (Notebook): 81.5\n* DT (Notebook): 73.89\n* NN (Notebook): 78.3\n\n# Conclusion\n\n* It is possible to model a successful tree based algorithm learning similar to the Neural Nets.","metadata":{}},{"cell_type":"code","source":"titanic_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\ndf = pd.read_csv(titanic_file)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:46:22.063525Z","iopub.execute_input":"2022-07-12T09:46:22.064215Z","iopub.status.idle":"2022-07-12T09:46:22.204657Z","shell.execute_reply.started":"2022-07-12T09:46:22.064180Z","shell.execute_reply":"2022-07-12T09:46:22.203635Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n32768/30874 [===============================] - 0s 0us/step\n40960/30874 [=======================================] - 0s 0us/step\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n0         0    male  22.0                   1      0   7.2500  Third  unknown   \n1         1  female  38.0                   1      0  71.2833  First        C   \n2         1  female  26.0                   0      0   7.9250  Third  unknown   \n3         1  female  35.0                   1      0  53.1000  First        C   \n4         0    male  28.0                   0      0   8.4583  Third  unknown   \n\n   embark_town alone  \n0  Southampton     n  \n1    Cherbourg     n  \n2  Southampton     y  \n3  Southampton     n  \n4   Queenstown     y  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>survived</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>n_siblings_spouses</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>class</th>\n      <th>deck</th>\n      <th>embark_town</th>\n      <th>alone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>Third</td>\n      <td>unknown</td>\n      <td>Southampton</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>First</td>\n      <td>C</td>\n      <td>Cherbourg</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>Third</td>\n      <td>unknown</td>\n      <td>Southampton</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>First</td>\n      <td>C</td>\n      <td>Southampton</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>male</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.4583</td>\n      <td>Third</td>\n      <td>unknown</td>\n      <td>Queenstown</td>\n      <td>y</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[list(df.select_dtypes(include = 'object').columns)] = df[list(df.select_dtypes(include = 'object').columns)].astype('string')\n\nTARGET_FEATURE_NAME = \"survived\"\nCATEGORICAL_FEATURES = list(df.select_dtypes(include = 'string').columns)\nNUMERIC_FEATURES =  list(df.select_dtypes(exclude = 'string').columns)[1:]\nFEATURE_NAMES = list(df.columns)\n\nCATEGORICAL_FEATURES_WITH_VOCABULARY = {\n    'sex': sorted(list(df['sex'].unique())),\n    'class': sorted(list(df['class'].unique())),\n    'deck': sorted(list(df['deck'].unique())),\n    'embark_town': sorted(list(df['embark_town'].unique())),\n    'alone': sorted(list(df['alone'].unique())),\n}","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:46:22.205787Z","iopub.execute_input":"2022-07-12T09:46:22.206898Z","iopub.status.idle":"2022-07-12T09:46:22.243358Z","shell.execute_reply.started":"2022-07-12T09:46:22.206859Z","shell.execute_reply":"2022-07-12T09:46:22.242251Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train,test = train_test_split(df,random_state = 42)\ntrain.to_csv('train_dataset.csv',index = False, header = False)\ntest.to_csv('test_dataset.csv',index = False, header = False)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:46:22.247096Z","iopub.execute_input":"2022-07-12T09:46:22.250773Z","iopub.status.idle":"2022-07-12T09:46:22.271965Z","shell.execute_reply.started":"2022-07-12T09:46:22.250688Z","shell.execute_reply":"2022-07-12T09:46:22.269892Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\n\ntrain_ds = tf.data.experimental.make_csv_dataset(\"./train_dataset.csv\",\n                                                batch_size = BATCH_SIZE,\n                                                column_names = FEATURE_NAMES,\n                                                label_name = TARGET_FEATURE_NAME,\n                                                num_epochs = 2,\n                                                header = False,\n                                                 shuffle = True\n                                                )\ntest_ds = tf.data.experimental.make_csv_dataset(\"./test_dataset.csv\",\n                                                batch_size = BATCH_SIZE,\n                                                column_names = FEATURE_NAMES,\n                                                label_name = TARGET_FEATURE_NAME,\n                                                num_epochs = 1,\n                                                header = False,\n                                                )","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:46:22.274756Z","iopub.execute_input":"2022-07-12T09:46:22.275934Z","iopub.status.idle":"2022-07-12T09:46:22.491796Z","shell.execute_reply.started":"2022-07-12T09:46:22.275864Z","shell.execute_reply":"2022-07-12T09:46:22.489875Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2022-07-12 09:46:22.301021: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_inputs():\n    inputs = {}\n    for feature_name in FEATURE_NAMES:\n        if feature_name in NUMERIC_FEATURES:\n            inputs[feature_name] = layers.Input(shape = (), dtype = tf.float32, name = feature_name)\n        elif feature_name in CATEGORICAL_FEATURES:\n            inputs[feature_name] = layers.Input(shape = (), dtype = tf.string, name = feature_name)\n    return inputs\n\ndef encode_features(inputs):\n    encoded_features = []\n    for feature_name in FEATURE_NAMES:\n        if feature_name in NUMERIC_FEATURES:\n            encoded_feature = tf.expand_dims(inputs[feature_name],-1)\n        elif feature_name in CATEGORICAL_FEATURES:\n            vocab = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n            lookup = layers.StringLookup(vocabulary = vocab, output_mode = \"one_hot\")\n            encoded_feature = lookup(inputs[feature_name])\n        else:\n            continue\n        encoded_features.append(encoded_feature)\n    \n    return encoded_features","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:46:22.494021Z","iopub.execute_input":"2022-07-12T09:46:22.495339Z","iopub.status.idle":"2022-07-12T09:46:22.509629Z","shell.execute_reply.started":"2022-07-12T09:46:22.495264Z","shell.execute_reply":"2022-07-12T09:46:22.508375Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# 1. Neural Networks","metadata":{}},{"cell_type":"code","source":"inputs = create_inputs()\nencoded_features = encode_features(inputs)\nencoded_features = layers.concatenate(encoded_features)\nx = layers.Dense(50, activation = 'relu')(encoded_features)\nx = layers.Dense(50, activation = 'relu')(x)\noutput = layers.Dense(1,activation ='sigmoid')(x)\n\nnn_model = keras.Model(inputs,output)\n\nnn_model.compile(\n    optimizer = 'adam',\n    loss = 'binary_crossentropy',\n    metrics = ['binary_accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:46:22.511005Z","iopub.execute_input":"2022-07-12T09:46:22.512260Z","iopub.status.idle":"2022-07-12T09:46:22.758122Z","shell.execute_reply.started":"2022-07-12T09:46:22.512214Z","shell.execute_reply":"2022-07-12T09:46:22.756570Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True)\nnn_model.fit(train_ds,validation_data = test_ds,epochs = 20, callbacks = [callback])","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:46:57.091972Z","iopub.execute_input":"2022-07-12T09:46:57.092418Z","iopub.status.idle":"2022-07-12T09:47:04.314351Z","shell.execute_reply.started":"2022-07-12T09:46:57.092379Z","shell.execute_reply":"2022-07-12T09:47:04.311826Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2022-07-12 09:46:57.158535: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n15/15 [==============================] - 2s 46ms/step - loss: 0.8400 - binary_accuracy: 0.6053 - val_loss: 0.6430 - val_binary_accuracy: 0.6943\nEpoch 2/20\n15/15 [==============================] - 0s 11ms/step - loss: 0.6480 - binary_accuracy: 0.6585 - val_loss: 0.6349 - val_binary_accuracy: 0.6688\nEpoch 3/20\n15/15 [==============================] - 0s 12ms/step - loss: 0.6174 - binary_accuracy: 0.6830 - val_loss: 0.5691 - val_binary_accuracy: 0.7197\nEpoch 4/20\n15/15 [==============================] - 0s 12ms/step - loss: 0.5611 - binary_accuracy: 0.7309 - val_loss: 0.5540 - val_binary_accuracy: 0.7834\nEpoch 5/20\n15/15 [==============================] - 0s 13ms/step - loss: 0.5455 - binary_accuracy: 0.7340 - val_loss: 0.5268 - val_binary_accuracy: 0.7452\nEpoch 6/20\n15/15 [==============================] - 0s 12ms/step - loss: 0.5230 - binary_accuracy: 0.7521 - val_loss: 0.5227 - val_binary_accuracy: 0.8089\nEpoch 7/20\n15/15 [==============================] - 0s 14ms/step - loss: 0.5176 - binary_accuracy: 0.7553 - val_loss: 0.5032 - val_binary_accuracy: 0.7389\nEpoch 8/20\n15/15 [==============================] - 0s 14ms/step - loss: 0.5151 - binary_accuracy: 0.7585 - val_loss: 0.4819 - val_binary_accuracy: 0.7771\nEpoch 9/20\n15/15 [==============================] - 0s 17ms/step - loss: 0.4823 - binary_accuracy: 0.8000 - val_loss: 0.4906 - val_binary_accuracy: 0.7962\nEpoch 10/20\n15/15 [==============================] - 0s 19ms/step - loss: 0.4533 - binary_accuracy: 0.8011 - val_loss: 0.4873 - val_binary_accuracy: 0.7707\nEpoch 11/20\n15/15 [==============================] - 0s 12ms/step - loss: 0.4357 - binary_accuracy: 0.8085 - val_loss: 0.5026 - val_binary_accuracy: 0.7898\nEpoch 12/20\n15/15 [==============================] - 0s 11ms/step - loss: 0.4471 - binary_accuracy: 0.8106 - val_loss: 0.4944 - val_binary_accuracy: 0.7452\nEpoch 13/20\n15/15 [==============================] - 0s 11ms/step - loss: 0.4429 - binary_accuracy: 0.8074 - val_loss: 0.4626 - val_binary_accuracy: 0.7834\nEpoch 14/20\n15/15 [==============================] - 0s 12ms/step - loss: 0.4730 - binary_accuracy: 0.8011 - val_loss: 0.5695 - val_binary_accuracy: 0.7389\nEpoch 15/20\n15/15 [==============================] - 0s 13ms/step - loss: 0.4652 - binary_accuracy: 0.8106 - val_loss: 0.4745 - val_binary_accuracy: 0.7643\nEpoch 16/20\n15/15 [==============================] - 0s 13ms/step - loss: 0.4268 - binary_accuracy: 0.8181 - val_loss: 0.4874 - val_binary_accuracy: 0.7389\nEpoch 17/20\n15/15 [==============================] - 0s 13ms/step - loss: 0.4355 - binary_accuracy: 0.8170 - val_loss: 0.4983 - val_binary_accuracy: 0.7834\nEpoch 18/20\n15/15 [==============================] - 0s 15ms/step - loss: 0.4239 - binary_accuracy: 0.8181 - val_loss: 0.4973 - val_binary_accuracy: 0.7771\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f4cc4546790>"},"metadata":{}}]},{"cell_type":"code","source":"nn_model.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:47:04.317193Z","iopub.execute_input":"2022-07-12T09:47:04.318206Z","iopub.status.idle":"2022-07-12T09:47:04.459839Z","shell.execute_reply.started":"2022-07-12T09:47:04.318140Z","shell.execute_reply":"2022-07-12T09:47:04.458550Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"3/3 [==============================] - 0s 7ms/step - loss: 0.4626 - binary_accuracy: 0.7834\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[0.4626370966434479, 0.7834395170211792]"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2. Neural Decision Trees ","metadata":{}},{"cell_type":"code","source":"class NeuralDecisionTree(keras.Model):\n    def __init__(self,depth,num_features,used_features_rate,num_classes):\n        super(NeuralDecisionTree, self).__init__()\n        self.depth = depth\n        self.num_leaves = 2**depth\n        self.num_classes = num_classes\n        self.step_counter = 1\n        num_used_features = int(num_features * used_features_rate)\n        one_hot = np.eye(num_features)\n        sampled_feature_indices = np.random.choice(np.arange(num_features), num_used_features, replace = False)\n        self.used_features_mask = one_hot[sampled_feature_indices]\n        \n        self.pi = tf.Variable(\n        initial_value = tf.random_normal_initializer()(\n        shape = [self.num_leaves,self.num_classes]),\n            dtype = tf.float32,\n            trainable = True)\n        \n        self.decision_fn = layers.Dense(units = self.num_leaves,\n        activation = \"sigmoid\",name = \"decision\")\n        \n    def call(self,features):\n\n        batch_size = tf.shape(features)[0]\n        features = tf.matmul(\n        features,self.used_features_mask,transpose_b = True)\n       \n\n        decisions = tf.expand_dims(\n            self.decision_fn(features),axis = 2\n        )\n\n        decisions = layers.concatenate(\n            [decisions,1-decisions], axis = 2\n        )\n\n        \n        mu = tf.ones([batch_size,1,1])\n        \n\n        begin_idx = 1\n        end_idx = 2\n\n        \n        for level in range(self.depth):\n            mu = tf.reshape(mu,[batch_size,-1,1])\n            mu = tf.tile(mu,(1,1,2))\n            level_decisions = decisions[\n                :,begin_idx:end_idx,:\n            ]\n            mu = mu * level_decisions\n            begin_idx = end_idx\n            end_idx = begin_idx + 2**(level+1)\n        \n        mu = tf.reshape(mu,[batch_size,self.num_leaves])\n       \n\n        probabilities = keras.activations.sigmoid(self.pi)\n       \n        outputs = tf.matmul(mu,probabilities)\n        \n    \n        return outputs","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:47:04.462046Z","iopub.execute_input":"2022-07-12T09:47:04.462485Z","iopub.status.idle":"2022-07-12T09:47:04.679863Z","shell.execute_reply.started":"2022-07-12T09:47:04.462450Z","shell.execute_reply":"2022-07-12T09:47:04.678314Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"neural_decision_params = {\n    'depth' : 10,\n'num_features' : 28,\n'num_classes' : 2,\n'used_features_rate' : 1.0}\n\ninputs = create_inputs()\nencoded_features = encode_features(inputs)\nfeatures = layers.concatenate(encoded_features)\noutputs = NeuralDecisionTree(**neural_decision_params)(features)\nneural_decision_tree_model = tf.keras.Model(inputs,outputs)\n\nneural_decision_tree_model.compile(\n    optimizer = 'adam',\n    loss = 'binary_crossentropy',\n    metrics = [\"binary_accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:47:04.682754Z","iopub.execute_input":"2022-07-12T09:47:04.683156Z","iopub.status.idle":"2022-07-12T09:47:05.100210Z","shell.execute_reply.started":"2022-07-12T09:47:04.683124Z","shell.execute_reply":"2022-07-12T09:47:05.098820Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"neural_decision_tree_model.fit(\n    train_ds,epochs = 30,\n    validation_data = test_ds,\n    callbacks = [callback]\n\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:47:05.101590Z","iopub.execute_input":"2022-07-12T09:47:05.101935Z","iopub.status.idle":"2022-07-12T09:47:19.500605Z","shell.execute_reply.started":"2022-07-12T09:47:05.101904Z","shell.execute_reply":"2022-07-12T09:47:19.499093Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/30\n15/15 [==============================] - 3s 60ms/step - loss: 0.6916 - binary_accuracy: 0.6016 - val_loss: 0.6881 - val_binary_accuracy: 0.6752\nEpoch 2/30\n15/15 [==============================] - 0s 22ms/step - loss: 0.6861 - binary_accuracy: 0.6633 - val_loss: 0.6823 - val_binary_accuracy: 0.6752\nEpoch 3/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6806 - binary_accuracy: 0.6745 - val_loss: 0.6764 - val_binary_accuracy: 0.6656\nEpoch 4/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6749 - binary_accuracy: 0.6745 - val_loss: 0.6703 - val_binary_accuracy: 0.6624\nEpoch 5/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6696 - binary_accuracy: 0.6777 - val_loss: 0.6654 - val_binary_accuracy: 0.6688\nEpoch 6/30\n15/15 [==============================] - 0s 20ms/step - loss: 0.6648 - binary_accuracy: 0.6824 - val_loss: 0.6611 - val_binary_accuracy: 0.6624\nEpoch 7/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6606 - binary_accuracy: 0.6840 - val_loss: 0.6567 - val_binary_accuracy: 0.6720\nEpoch 8/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6567 - binary_accuracy: 0.6867 - val_loss: 0.6529 - val_binary_accuracy: 0.6815\nEpoch 9/30\n15/15 [==============================] - 0s 22ms/step - loss: 0.6530 - binary_accuracy: 0.6947 - val_loss: 0.6489 - val_binary_accuracy: 0.6879\nEpoch 10/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6494 - binary_accuracy: 0.7005 - val_loss: 0.6449 - val_binary_accuracy: 0.6943\nEpoch 11/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6461 - binary_accuracy: 0.7059 - val_loss: 0.6413 - val_binary_accuracy: 0.6975\nEpoch 12/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6427 - binary_accuracy: 0.7133 - val_loss: 0.6373 - val_binary_accuracy: 0.7261\nEpoch 13/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6394 - binary_accuracy: 0.7181 - val_loss: 0.6338 - val_binary_accuracy: 0.7261\nEpoch 14/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6361 - binary_accuracy: 0.7213 - val_loss: 0.6301 - val_binary_accuracy: 0.7261\nEpoch 15/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6328 - binary_accuracy: 0.7287 - val_loss: 0.6267 - val_binary_accuracy: 0.7261\nEpoch 16/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6295 - binary_accuracy: 0.7287 - val_loss: 0.6231 - val_binary_accuracy: 0.7261\nEpoch 17/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6263 - binary_accuracy: 0.7298 - val_loss: 0.6193 - val_binary_accuracy: 0.7261\nEpoch 18/30\n15/15 [==============================] - 0s 22ms/step - loss: 0.6230 - binary_accuracy: 0.7319 - val_loss: 0.6160 - val_binary_accuracy: 0.7357\nEpoch 19/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6196 - binary_accuracy: 0.7378 - val_loss: 0.6124 - val_binary_accuracy: 0.7389\nEpoch 20/30\n15/15 [==============================] - 0s 25ms/step - loss: 0.6162 - binary_accuracy: 0.7420 - val_loss: 0.6086 - val_binary_accuracy: 0.7389\nEpoch 21/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6125 - binary_accuracy: 0.7426 - val_loss: 0.6053 - val_binary_accuracy: 0.7389\nEpoch 22/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6092 - binary_accuracy: 0.7500 - val_loss: 0.6016 - val_binary_accuracy: 0.7420\nEpoch 23/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6048 - binary_accuracy: 0.7500 - val_loss: 0.5982 - val_binary_accuracy: 0.7484\nEpoch 24/30\n15/15 [==============================] - 0s 21ms/step - loss: 0.6010 - binary_accuracy: 0.7521 - val_loss: 0.5949 - val_binary_accuracy: 0.7580\nEpoch 25/30\n15/15 [==============================] - 0s 23ms/step - loss: 0.5972 - binary_accuracy: 0.7484 - val_loss: 0.5911 - val_binary_accuracy: 0.7611\nEpoch 26/30\n15/15 [==============================] - 0s 19ms/step - loss: 0.5929 - binary_accuracy: 0.7548 - val_loss: 0.5876 - val_binary_accuracy: 0.7739\nEpoch 27/30\n15/15 [==============================] - 0s 19ms/step - loss: 0.5891 - binary_accuracy: 0.7527 - val_loss: 0.5836 - val_binary_accuracy: 0.7834\nEpoch 28/30\n15/15 [==============================] - 0s 19ms/step - loss: 0.5850 - binary_accuracy: 0.7580 - val_loss: 0.5810 - val_binary_accuracy: 0.7898\nEpoch 29/30\n15/15 [==============================] - 0s 19ms/step - loss: 0.5810 - binary_accuracy: 0.7622 - val_loss: 0.5770 - val_binary_accuracy: 0.8312\nEpoch 30/30\n15/15 [==============================] - 0s 19ms/step - loss: 0.5768 - binary_accuracy: 0.7670 - val_loss: 0.5732 - val_binary_accuracy: 0.8153\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f4cbc0cbf10>"},"metadata":{}}]},{"cell_type":"code","source":"neural_decision_tree_model.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:47:36.951468Z","iopub.execute_input":"2022-07-12T09:47:36.952010Z","iopub.status.idle":"2022-07-12T09:47:37.129636Z","shell.execute_reply.started":"2022-07-12T09:47:36.951964Z","shell.execute_reply":"2022-07-12T09:47:37.128369Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"3/3 [==============================] - 0s 9ms/step - loss: 0.5732 - binary_accuracy: 0.8153\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[0.5732039213180542, 0.8152866363525391]"},"metadata":{}}]},{"cell_type":"markdown","source":"# 3.Decision Trees","metadata":{}},{"cell_type":"code","source":"# pandas preprocessing\ndf.sex = LabelEncoder().fit_transform(df.sex)\ndf.alone = LabelEncoder().fit_transform(df.alone)\ndf = pd.get_dummies(df,columns = ['class','deck','embark_town'])\ntrain,test = train_test_split(df,random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:47:19.502862Z","iopub.execute_input":"2022-07-12T09:47:19.503389Z","iopub.status.idle":"2022-07-12T09:47:19.521671Z","shell.execute_reply.started":"2022-07-12T09:47:19.503334Z","shell.execute_reply":"2022-07-12T09:47:19.520562Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tree_model = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\",random_state = 42)\ntree_model.fit(train.drop('survived',axis = 1),train.survived)\nprint('Accuracy score tree model: ',np.round(accuracy_score(test.survived,tree_model.predict(test.drop('survived',axis = 1)))*100,2))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:47:19.523204Z","iopub.execute_input":"2022-07-12T09:47:19.524086Z","iopub.status.idle":"2022-07-12T09:47:19.543260Z","shell.execute_reply.started":"2022-07-12T09:47:19.524043Z","shell.execute_reply":"2022-07-12T09:47:19.542246Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Accuracy score tree model:  73.89\n","output_type":"stream"}]},{"cell_type":"code","source":"tree_model = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\",random_state = 42)\ntree_model.fit(train.drop('survived',axis = 1),train.survived)\nprint('Accuracy score tree model: ',np.round(accuracy_score(test.survived,tree_model.predict(test.drop('survived',axis = 1)))*100,2))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:47:19.544817Z","iopub.execute_input":"2022-07-12T09:47:19.545699Z","iopub.status.idle":"2022-07-12T09:47:19.564495Z","shell.execute_reply.started":"2022-07-12T09:47:19.545665Z","shell.execute_reply":"2022-07-12T09:47:19.563683Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Accuracy score tree model:  73.89\n","output_type":"stream"}]}]}