{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz9bNNzo_BDS",
        "outputId": "3bfd28cd-365f-4cf9-fce8-a9dc8a105606"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33megedalgic\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "DOWNLOAD = False\n",
        "if DOWNLOAD:\n",
        "  !pip install ultralytics --quiet\n",
        "  !yolo settings wandb=True --quiet\n",
        "from pathlib import Path\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import kagglehub\n",
        "import wandb\n",
        "from google.colab import userdata\n",
        "from ultralytics import settings\n",
        "\n",
        "api_key = userdata.get('Wandb')\n",
        "wandb.login(key = api_key)\n",
        "settings.update({\"wandb\": True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfmxGS0pIHc9",
        "outputId": "bdd11364-1983-4600-cb60-c40187a0806b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Colab cache for faster access to the 'fruit-detection' dataset.\n"
          ]
        }
      ],
      "source": [
        "dataset_path = kagglehub.dataset_download(\"lakshaytyagi01/fruit-detection\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRAj4nbj_bt7"
      },
      "source": [
        "# Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1LzwoO6JBWW4"
      },
      "outputs": [],
      "source": [
        "def find_split_root(root: Path):\n",
        "    candidates = []\n",
        "    for p, dirs, files in os.walk(root):\n",
        "        p = Path(p)\n",
        "        if (p / \"train\" / \"images\").is_dir() and (p / \"valid\" / \"images\").is_dir():\n",
        "            candidates.append(p)\n",
        "    candidates = sorted(candidates, key=lambda x: (\"fruit\" not in x.as_posix().lower(), len(x.as_posix())))\n",
        "    return candidates[0] if candidates else None\n",
        "\n",
        "split_root = find_split_root(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6fmGuuOBkCo",
        "outputId": "eac0f95b-44be-4578-dd60-128f1edc8da3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info] Wrote data.yaml to: /content/data.yaml\n"
          ]
        }
      ],
      "source": [
        "train_images = split_root / \"train\" / \"images\"\n",
        "val_images   = split_root / \"valid\" / \"images\"\n",
        "test_images  = split_root / \"test\" / \"images\"\n",
        "\n",
        "names = [\n",
        "    \"Apple\", \"Banana\", \"Grape\", \"Orange\", \"Pineapple\", \"Watermelon\"\n",
        "]\n",
        "\n",
        "data_yaml_path = Path(\"/content/data.yaml\") if Path(\"/content\").exists() else Path.cwd() / \"data.yaml\"\n",
        "\n",
        "data_yaml_text = f\"\"\"\n",
        "# Auto-generated for Ultralytics\n",
        "path: {split_root.as_posix()}\n",
        "train: {train_images.as_posix()}\n",
        "val: {val_images.as_posix()}\n",
        "{'test: ' + test_images.as_posix() if test_images.is_dir() else ''}\n",
        "\n",
        "names: {names}\n",
        "nc: {len(names)}\n",
        "\"\"\".strip()\n",
        "\n",
        "with open(data_yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(data_yaml_text)\n",
        "print(f\"[Info] Wrote data.yaml to: {data_yaml_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPxzwbY2IgN3"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fdq9H5w_Aed"
      },
      "outputs": [],
      "source": [
        "TRAIN = False\n",
        "\n",
        "if TRAIN:\n",
        "  model = YOLO(\"yolo11n.pt\")\n",
        "  results = model.train(\n",
        "    data=str(data_yaml_path),\n",
        "    epochs = 5,\n",
        "    imgsz=640, #resoultion bigger the better but slower\n",
        "    batch=32,#batch size = -1 for automatic batch size selection\n",
        "    iou=0.6, #mape was calculated with iou=0.6\n",
        "    conf=0.001, #confidence threshold for object detection (True if above this value)\n",
        "    device=0, #use GPU\n",
        "    project=\"YOLO\",\n",
        "    name=\"coco_finetune\",\n",
        "    save_json=True,\n",
        "    #cache = True, #cache images for faster training; cache = \"disk\" to cache to disk (slower but better than nothing and more useful for large datasets)\n",
        "    #amp = True, #automatic mixed precision (faster training with less memory usage)\n",
        "    #optimizer = \"auto\", #select best optimizer automatically \n",
        "    #patience=... #early stopping\n",
        "    #also one can add data augmentation parameters here\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gETeU4IAHb00"
      },
      "source": [
        "# Notes\n",
        "\n",
        "* All the metrics, run logs and visualizations are stored in wandb. Only save the best weights manually or export the model all together."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
