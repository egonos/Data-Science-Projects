{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "mount_file_id": "1noQRj9EAQry7MQzjhFSWrGxfj0ATwDmK",
   "authorship_tag": "ABX9TyNeta4pob5iEf++pgcAaewy"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from tqdm import tqdm\n",
    "import json"
   ],
   "metadata": {
    "id": "YBjKXQJWCyh2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735373197315,
     "user_tz": -180,
     "elapsed": 43371,
     "user": {
      "displayName": "Egemen U\u011fur Dalg\u0131\u00e7",
      "userId": "05875523198878300823"
     }
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.random.manual_seed(5)\n",
    "\n",
    "#souce: https://huggingface.co/microsoft/Phi-3.5-mini-instruct\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3.5-mini-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")"
   ],
   "metadata": {
    "id": "cIt2c2aLC0c9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728,
     "referenced_widgets": [
      "7985f4f1acbe40dfa680b3b369fc5180",
      "7d337f8a83ab4896a6c1cb3ad7dd140c",
      "81f8553278df4650858c0a4876e3047b",
      "9a1cca8239194adb8779b87bc1b87264",
      "bf6a1ff98ca5485f827ab7113896784d",
      "3b34b8ff6d504917a6fbd7c5ba82bdd3",
      "5535c3ff319b4ebb82c3fbdbb84e6e90",
      "de8e35e8d7cf4ef4974d7e31e4fa9bc9",
      "52d8e6343806414f92e1d95df2dd9e96",
      "d297d7c9aa13478fba95ee7d97ed0b43",
      "bc8cc5a8984f4661ab2ffa3fa61143e9",
      "4159552056764fee8849873b3d671ec6",
      "a48beabafd604fa7a7151cb9a38f6bbc",
      "c84a661a45984d40a1e02fbc3f27e4f2",
      "37937dfc72c34ce396267798950a6c34",
      "532df79136f0400aa5f17258ed6c6a98",
      "99b9800717464de98b1707baad80192c",
      "de298dc14af6426e815fde75ba3425ab",
      "78b2b30903cc4d8db0084df157ea77ff",
      "73287be4fdf141dd9762e657e00c4fdd",
      "cb9d1a2ec72949efbde6d4dff745ae31",
      "7635ce711cab4d9c93961a61010bd77d",
      "35564b5626814fffb50cd227bbfa18ad",
      "19134adb40fb4d83872275e4ed956b32",
      "66b527396c8a40c5a0608c54c75146a1",
      "ada878f3055349dd80c100f431944206",
      "9b2cf143755e4936afd7b8b90b3eaef2",
      "4551f7698a534b8991c3927a78c1c277",
      "a18b7850f3fe46f5a049c05ba965a305",
      "813909783ad0455c903eaee01330cb2a",
      "e5ee0fae14f441f08cf71a436a6ad0c5",
      "6c53ec5e0f614d878ee12729a70dd079",
      "17356ad2e4aa4ea2bb21ffa109d81cec",
      "cac18e5a129742d5be71cf3c9c60a66b",
      "ef5cefeb014046799e1b8b6917e534fc",
      "1062769460df4eb8ab1d8a3a1991a6ad",
      "235864f5bc114f1b8975f4edbe768ee1",
      "d50d93901f8a4f41956fecb0faff2fb7",
      "22630d73f34648c09fb1d1f973e5b3ee",
      "b1d44a5181664df89a45beed72daab96",
      "578f74e819884c4e9ff86c9cc30a9405",
      "35a1a30721454140b1671f156277ec8e",
      "db6e94fa402f4894b26da074de4f9662",
      "1e316abdd1214a17b3020c86db5e6cb1",
      "6b1b9f2af91743859bb0071aaf5f8dde",
      "e1685320a2bc477c9fee48c5214b2233",
      "6b653b20b1bb40df930da0761f245ef2",
      "ee5a325c51884af9b8e66eed6945bc45",
      "c54b137f447c4a26931b91ef62e5841d",
      "daf92a813d5e4cb294642dc5f898f2c1",
      "4b72ef4c1ea74dda82f822ea8706f389",
      "a9aa42e1a98e4a36a5367f4ff743cb70",
      "665ce9583c2242a891aa707195318df8",
      "45d7fbf129684ff8908cc310f933f9f5",
      "46290721145f4838a0456aeae7ffa427",
      "e805b175b4ec4be681de893f1e1df7c6",
      "1f7749c025ec4e5a92ead1da6dfaeca2",
      "ed4866eee40044aa94c5e75efc7c586f",
      "5d006bd4df5f4ebaa3519870af72aac7",
      "73b7aa7e245a4839b2300aeb25bc729a",
      "6fa10ccb66ae4b8588d432b6f73e121c",
      "2c9ecdf4bd0a4d2f966e496dd5355f1c",
      "f9398ef7bec842a682f1bbcb22c8e6bc",
      "c9aa687f073c4f86adfbd49a99734bac",
      "1e411f20aa1147568a8809ed329ad210",
      "878913650d61437f98774d88f855a416",
      "3730d600976f4ae0957b5ca0a5451ae4",
      "f77076c59f7d49d08a2fd93a2412c514",
      "c2131d9ef1d94ab39cf2f4d4913aa73d",
      "375951f69c3740a58b66c67d6c0569b5",
      "b32e3e596a004b2f98ff42970067af9c",
      "1189f5ba1bfb4fafa79e9a33ea6ccafe",
      "8126aa1832b64e74902b888bdf90e721",
      "5c581db2b08842ecbfe66593896db472",
      "ddda68184c0645d78fbc0e0735a71056",
      "eab742f811024765b57bfcb19224f94f",
      "d150e5653c604b819b2c73b3217ad2d2",
      "6c701e5d8723466bbb2833184312963c",
      "33f9c2498fb44448be9b918615b48246",
      "e223dcd2fef04aae931ec7df3461ed37",
      "30cadb08b23142bfb4c0418e406764f0",
      "967cacb473c1420dac6de2344dde7133",
      "33869432c70c4630877e5f8689a06e40",
      "195e6e56b91e4d838716c8a8b7b69503",
      "a5e4d1c4e67f4109b5a852081dd91fbb",
      "caf088948d984de38480ceaee5fa64ec",
      "7287771c97ed471a966d69739f5aae19",
      "2a3df24a3f9843258c2e293f8d399089",
      "65acb0400a854fedbf445058a5318833",
      "2d07403b870548bca2f067ee1b78536c",
      "43b77eaf8af64f8b922be845ccd55f09",
      "4da2b46f0c7d4452a2016da745579d0c",
      "45d623fea6c34770b9c873d75187cc43",
      "034119c96a824732be389b2d7e40b222",
      "82001204c86e436aafa4c930405fe997",
      "641dd14315ed4a51aa6e62874e399ce2",
      "090d08e4c9124beaa46902148898a1ef",
      "7ef76e00835b46a08048a721f55b1c09",
      "46d1e77aa27844f593f8192aec1a6d83",
      "1198007ad57f4bdaae5d7e8b2f35920f",
      "6833e1bd4e0d475c86417913dfaa53a5",
      "f2329f5f956e459da3f1747054c729fa",
      "ac818e6306e140b3bc6cbdfec53bee86",
      "1bada33bccb947c7b60551dfc8d63569",
      "65b397d5ec464419a86eb700d0b78e41",
      "d251562c9e2248d6aa741bc4e63cd37c",
      "0961414957b7406baa20a2afdb1d6817",
      "d19051c8578442b488085a5abb98c337",
      "79a917efffc94c9fbe09eeddcf6d6d9c",
      "1c77c873b3bd4060b88a768325d26a94",
      "32787fc0a43c42cd9ac620f5c4378d0c",
      "c5049f2ff47a4531be2a51ab8bd2e2dc",
      "2e5347770f174098867b34f025e80c4d",
      "e5936c2c5aef4a69afd99dcbf39f348d",
      "5f4975b0b80e48f18ab3b02af5d34253",
      "7485681bddf54ed4a52ab81b4f50053c",
      "1e7b123c41604f09a63bb8b7f230fae4",
      "57555acc6f4e4b089e2c7b33d2c7b47a",
      "38255950c007408486d45e4e0a55cb17",
      "326de4c08bbf40a596b951b8eb97c795",
      "6a3ad664c5b747b4bb1207df56346f3c",
      "3c55c5496cdf4e769c2cff1ae05a8d2f",
      "2510836a73aa414ea980d17da1a496b4",
      "1fdc806d4a87474c92254cd55a7ff5f8",
      "32e018a2479e4d9c88305f38b688ec6e",
      "1b7dd38a209149529523c867cb71a9b0",
      "0936f386560944df9787ab406ce4fe93",
      "a6985e57b29e4122aab2e4c25ffb0459",
      "46cb71ea12064a2cb1db88b33934f87d",
      "88d8aef170244b36af0bdb40239381d1",
      "f904d52dd27a4eb2b03c97330bad1de4",
      "7e5e6e133c9d478bb078e08c0726626a",
      "9340a03c0bda45e8af1b2d91e14663c2",
      "9c2bb637068c4b49b547e4cb93a75acc",
      "56ec20aea84c4bbb896d9c06b5ab33a1",
      "32d695e6f65b4608a9156363169e26bf",
      "281e88cc125d465f9a5101d606215294",
      "ae4875ae90fb495793cfc3f7f4c08e5d",
      "7704db1e9b554068b4d8fd9d55fa7dc9",
      "96437d7e669946cb815aebad9f8d5829",
      "2b6c12b953cf44a59d44f6a05d67275b",
      "f07ef36c31364ccdbad7d1257d65e883",
      "373e4c2672b343beae508dcc5161248d",
      "609d80fde25d4fff99deb58b54f61b73",
      "a647061c5951423db053fd266a9dcc69",
      "c5cf652014b0401398e34a709350b330",
      "460bc2817b054bc68ef7ca3fe8cb3fd7",
      "420f2e6859eb4884852fad36bed8de03",
      "52ccdd9c84d74f9ea6e2ee4dda9f4e7a",
      "bb8405554f304a2a9c7e1e6a6a37d7b1",
      "fd2d2a6ef9a846e2bc3f118d9320eef8",
      "20336e37dc8940ebae4e4e17578dbb5c",
      "c5d8e265e7194987945dbfe3328ca15b",
      "ead7fff3f0fe428298d9b3036bb627f2"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735373425583,
     "user_tz": -180,
     "elapsed": 220649,
     "user": {
      "displayName": "Egemen U\u011fur Dalg\u0131\u00e7",
      "userId": "05875523198878300823"
     }
    },
    "outputId": "d3ed898f-f33c-4439-87f4-fe1782a24559"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/3.45k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7985f4f1acbe40dfa680b3b369fc5180"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4159552056764fee8849873b3d671ec6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35564b5626814fffb50cd227bbfa18ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cac18e5a129742d5be71cf3c9c60a66b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b1b9f2af91743859bb0071aaf5f8dde"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e805b175b4ec4be681de893f1e1df7c6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3730d600976f4ae0957b5ca0a5451ae4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c701e5d8723466bbb2833184312963c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65acb0400a854fedbf445058a5318833"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.98k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1198007ad57f4bdaae5d7e8b2f35920f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32787fc0a43c42cd9ac620f5c4378d0c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c55c5496cdf4e769c2cff1ae05a8d2f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9340a03c0bda45e8af1b2d91e14663c2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "609d80fde25d4fff99deb58b54f61b73"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2ihTNC9BO9r",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735373834851,
     "user_tz": -180,
     "elapsed": 394745,
     "user": {
      "displayName": "Egemen U\u011fur Dalg\u0131\u00e7",
      "userId": "05875523198878300823"
     }
    },
    "outputId": "1e605d5f-a2a2-48a6-9fc4-670289ad1ec8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/200 [00:00<?, ?it/s]Device set to use cuda\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n",
      "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n",
      "  0%|          | 1/200 [00:04<14:01,  4.23s/it]Device set to use cuda\n",
      "  1%|          | 2/200 [00:05<08:53,  2.70s/it]Device set to use cuda\n",
      "  2%|\u258f         | 3/200 [00:07<07:01,  2.14s/it]Device set to use cuda\n",
      "  2%|\u258f         | 4/200 [00:09<06:54,  2.12s/it]Device set to use cuda\n",
      "  2%|\u258e         | 5/200 [00:11<07:01,  2.16s/it]Device set to use cuda\n",
      "  3%|\u258e         | 6/200 [00:12<06:03,  1.88s/it]Device set to use cuda\n",
      "  4%|\u258e         | 7/200 [00:14<05:29,  1.71s/it]Device set to use cuda\n",
      "  4%|\u258d         | 8/200 [00:16<05:43,  1.79s/it]Device set to use cuda\n",
      "  4%|\u258d         | 9/200 [00:17<05:28,  1.72s/it]Device set to use cuda\n",
      "  5%|\u258c         | 10/200 [00:20<05:52,  1.86s/it]Device set to use cuda\n",
      "  6%|\u258c         | 11/200 [00:23<07:40,  2.44s/it]Device set to use cuda\n",
      "  6%|\u258c         | 12/200 [00:28<09:22,  2.99s/it]Device set to use cuda\n",
      "  6%|\u258b         | 13/200 [00:30<08:27,  2.71s/it]Device set to use cuda\n",
      "  7%|\u258b         | 14/200 [00:31<07:15,  2.34s/it]Device set to use cuda\n",
      "  8%|\u258a         | 15/200 [00:33<06:52,  2.23s/it]Device set to use cuda\n",
      "  8%|\u258a         | 16/200 [00:35<06:33,  2.14s/it]Device set to use cuda\n",
      "  8%|\u258a         | 17/200 [00:37<06:23,  2.09s/it]Device set to use cuda\n",
      "  9%|\u2589         | 18/200 [00:42<08:40,  2.86s/it]Device set to use cuda\n",
      " 10%|\u2589         | 19/200 [00:43<07:37,  2.53s/it]Device set to use cuda\n",
      " 10%|\u2588         | 20/200 [00:46<07:18,  2.43s/it]Device set to use cuda\n",
      " 10%|\u2588         | 21/200 [00:48<06:48,  2.28s/it]Device set to use cuda\n",
      " 11%|\u2588         | 22/200 [00:50<06:40,  2.25s/it]Device set to use cuda\n",
      " 12%|\u2588\u258f        | 23/200 [00:52<06:48,  2.31s/it]Device set to use cuda\n",
      " 12%|\u2588\u258f        | 24/200 [00:54<06:26,  2.19s/it]Device set to use cuda\n",
      " 12%|\u2588\u258e        | 25/200 [00:56<06:16,  2.15s/it]Device set to use cuda\n",
      " 13%|\u2588\u258e        | 26/200 [00:58<06:15,  2.16s/it]Device set to use cuda\n",
      " 14%|\u2588\u258e        | 27/200 [01:00<05:31,  1.92s/it]Device set to use cuda\n",
      " 14%|\u2588\u258d        | 28/200 [01:01<05:20,  1.86s/it]Device set to use cuda\n",
      " 14%|\u2588\u258d        | 29/200 [01:03<05:14,  1.84s/it]Device set to use cuda\n",
      " 15%|\u2588\u258c        | 30/200 [01:05<05:06,  1.80s/it]Device set to use cuda\n",
      " 16%|\u2588\u258c        | 31/200 [01:06<04:53,  1.74s/it]Device set to use cuda\n",
      " 16%|\u2588\u258c        | 32/200 [01:09<05:27,  1.95s/it]Device set to use cuda\n",
      " 16%|\u2588\u258b        | 33/200 [01:11<05:28,  1.97s/it]Device set to use cuda\n",
      " 17%|\u2588\u258b        | 34/200 [01:12<05:04,  1.84s/it]Device set to use cuda\n",
      " 18%|\u2588\u258a        | 35/200 [01:14<04:32,  1.65s/it]Device set to use cuda\n",
      " 18%|\u2588\u258a        | 36/200 [01:15<04:24,  1.61s/it]Device set to use cuda\n",
      " 18%|\u2588\u258a        | 37/200 [01:17<04:50,  1.78s/it]Device set to use cuda\n",
      " 19%|\u2588\u2589        | 38/200 [01:20<05:11,  1.92s/it]Device set to use cuda\n",
      " 20%|\u2588\u2589        | 39/200 [01:22<05:33,  2.07s/it]Device set to use cuda\n",
      " 20%|\u2588\u2588        | 40/200 [01:24<05:21,  2.01s/it]Device set to use cuda\n",
      " 20%|\u2588\u2588        | 41/200 [01:26<05:19,  2.01s/it]Device set to use cuda\n",
      " 21%|\u2588\u2588        | 42/200 [01:28<05:25,  2.06s/it]Device set to use cuda\n",
      " 22%|\u2588\u2588\u258f       | 43/200 [01:30<05:20,  2.04s/it]Device set to use cuda\n",
      " 22%|\u2588\u2588\u258f       | 44/200 [01:32<05:25,  2.08s/it]Device set to use cuda\n",
      " 22%|\u2588\u2588\u258e       | 45/200 [01:34<05:22,  2.08s/it]Device set to use cuda\n",
      " 23%|\u2588\u2588\u258e       | 46/200 [01:37<05:44,  2.24s/it]Device set to use cuda\n",
      " 24%|\u2588\u2588\u258e       | 47/200 [01:39<05:12,  2.05s/it]Device set to use cuda\n",
      " 24%|\u2588\u2588\u258d       | 48/200 [01:41<05:05,  2.01s/it]Device set to use cuda\n",
      " 24%|\u2588\u2588\u258d       | 49/200 [01:42<04:53,  1.94s/it]Device set to use cuda\n",
      " 25%|\u2588\u2588\u258c       | 50/200 [01:44<04:47,  1.92s/it]Device set to use cuda\n",
      " 26%|\u2588\u2588\u258c       | 51/200 [01:46<04:41,  1.89s/it]Device set to use cuda\n",
      " 26%|\u2588\u2588\u258c       | 52/200 [01:48<04:31,  1.84s/it]Device set to use cuda\n",
      " 26%|\u2588\u2588\u258b       | 53/200 [01:50<05:03,  2.07s/it]Device set to use cuda\n",
      " 27%|\u2588\u2588\u258b       | 54/200 [01:52<04:55,  2.03s/it]Device set to use cuda\n",
      " 28%|\u2588\u2588\u258a       | 55/200 [01:54<04:46,  1.98s/it]Device set to use cuda\n",
      " 28%|\u2588\u2588\u258a       | 56/200 [01:56<04:44,  1.98s/it]Device set to use cuda\n",
      " 28%|\u2588\u2588\u258a       | 57/200 [01:58<04:22,  1.84s/it]Device set to use cuda\n",
      " 29%|\u2588\u2588\u2589       | 58/200 [02:00<04:36,  1.94s/it]Device set to use cuda\n",
      " 30%|\u2588\u2588\u2589       | 59/200 [02:02<04:40,  1.99s/it]Device set to use cuda\n",
      " 30%|\u2588\u2588\u2588       | 60/200 [02:04<05:05,  2.18s/it]Device set to use cuda\n",
      " 30%|\u2588\u2588\u2588       | 61/200 [02:07<05:03,  2.19s/it]Device set to use cuda\n",
      " 31%|\u2588\u2588\u2588       | 62/200 [02:08<04:40,  2.03s/it]Device set to use cuda\n",
      " 32%|\u2588\u2588\u2588\u258f      | 63/200 [02:11<04:45,  2.08s/it]Device set to use cuda\n",
      " 32%|\u2588\u2588\u2588\u258f      | 64/200 [02:12<04:34,  2.02s/it]Device set to use cuda\n",
      " 32%|\u2588\u2588\u2588\u258e      | 65/200 [02:14<04:17,  1.91s/it]Device set to use cuda\n",
      " 33%|\u2588\u2588\u2588\u258e      | 66/200 [02:16<03:57,  1.77s/it]Device set to use cuda\n",
      " 34%|\u2588\u2588\u2588\u258e      | 67/200 [02:18<04:09,  1.88s/it]Device set to use cuda\n",
      " 34%|\u2588\u2588\u2588\u258d      | 68/200 [02:20<04:14,  1.93s/it]Device set to use cuda\n",
      " 34%|\u2588\u2588\u2588\u258d      | 69/200 [02:22<04:15,  1.95s/it]Device set to use cuda\n",
      " 35%|\u2588\u2588\u2588\u258c      | 70/200 [02:23<03:54,  1.80s/it]Device set to use cuda\n",
      " 36%|\u2588\u2588\u2588\u258c      | 71/200 [02:25<04:05,  1.90s/it]Device set to use cuda\n",
      " 36%|\u2588\u2588\u2588\u258c      | 72/200 [02:28<04:16,  2.00s/it]Device set to use cuda\n",
      " 36%|\u2588\u2588\u2588\u258b      | 73/200 [02:30<04:20,  2.05s/it]Device set to use cuda\n",
      " 37%|\u2588\u2588\u2588\u258b      | 74/200 [02:32<04:14,  2.02s/it]Device set to use cuda\n",
      " 38%|\u2588\u2588\u2588\u258a      | 75/200 [02:34<04:09,  1.99s/it]Device set to use cuda\n",
      " 38%|\u2588\u2588\u2588\u258a      | 76/200 [02:35<03:39,  1.77s/it]Device set to use cuda\n",
      " 38%|\u2588\u2588\u2588\u258a      | 77/200 [02:37<03:43,  1.82s/it]Device set to use cuda\n",
      " 39%|\u2588\u2588\u2588\u2589      | 78/200 [02:39<03:43,  1.83s/it]Device set to use cuda\n",
      " 40%|\u2588\u2588\u2588\u2589      | 79/200 [02:41<03:47,  1.88s/it]Device set to use cuda\n",
      " 40%|\u2588\u2588\u2588\u2588      | 80/200 [02:43<04:01,  2.01s/it]Device set to use cuda\n",
      " 40%|\u2588\u2588\u2588\u2588      | 81/200 [02:45<04:03,  2.05s/it]Device set to use cuda\n",
      " 41%|\u2588\u2588\u2588\u2588      | 82/200 [02:47<04:02,  2.05s/it]Device set to use cuda\n",
      " 42%|\u2588\u2588\u2588\u2588\u258f     | 83/200 [02:49<04:02,  2.08s/it]Device set to use cuda\n",
      " 42%|\u2588\u2588\u2588\u2588\u258f     | 84/200 [02:51<03:39,  1.89s/it]Device set to use cuda\n",
      " 42%|\u2588\u2588\u2588\u2588\u258e     | 85/200 [02:53<03:47,  1.98s/it]Device set to use cuda\n",
      " 43%|\u2588\u2588\u2588\u2588\u258e     | 86/200 [02:55<03:53,  2.04s/it]Device set to use cuda\n",
      " 44%|\u2588\u2588\u2588\u2588\u258e     | 87/200 [02:58<04:09,  2.21s/it]Device set to use cuda\n",
      " 44%|\u2588\u2588\u2588\u2588\u258d     | 88/200 [03:00<04:06,  2.20s/it]Device set to use cuda\n",
      " 44%|\u2588\u2588\u2588\u2588\u258d     | 89/200 [03:02<03:52,  2.10s/it]Device set to use cuda\n",
      " 45%|\u2588\u2588\u2588\u2588\u258c     | 90/200 [03:03<03:22,  1.84s/it]Device set to use cuda\n",
      " 46%|\u2588\u2588\u2588\u2588\u258c     | 91/200 [03:05<03:32,  1.95s/it]Device set to use cuda\n",
      " 46%|\u2588\u2588\u2588\u2588\u258c     | 92/200 [03:06<03:08,  1.75s/it]Device set to use cuda\n",
      " 46%|\u2588\u2588\u2588\u2588\u258b     | 93/200 [03:08<03:06,  1.74s/it]Device set to use cuda\n",
      " 47%|\u2588\u2588\u2588\u2588\u258b     | 94/200 [03:10<03:14,  1.83s/it]Device set to use cuda\n",
      " 48%|\u2588\u2588\u2588\u2588\u258a     | 95/200 [03:12<03:18,  1.89s/it]Device set to use cuda\n",
      " 48%|\u2588\u2588\u2588\u2588\u258a     | 96/200 [03:14<03:22,  1.94s/it]Device set to use cuda\n",
      " 48%|\u2588\u2588\u2588\u2588\u258a     | 97/200 [03:16<03:21,  1.96s/it]Device set to use cuda\n",
      " 49%|\u2588\u2588\u2588\u2588\u2589     | 98/200 [03:18<03:04,  1.81s/it]Device set to use cuda\n",
      " 50%|\u2588\u2588\u2588\u2588\u2589     | 99/200 [03:20<03:12,  1.91s/it]Device set to use cuda\n",
      " 50%|\u2588\u2588\u2588\u2588\u2588     | 100/200 [03:22<03:01,  1.82s/it]Device set to use cuda\n",
      " 50%|\u2588\u2588\u2588\u2588\u2588     | 101/200 [03:23<02:49,  1.72s/it]Device set to use cuda\n",
      " 51%|\u2588\u2588\u2588\u2588\u2588     | 102/200 [03:26<03:16,  2.01s/it]Device set to use cuda\n",
      " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 103/200 [03:27<03:01,  1.87s/it]Device set to use cuda\n",
      " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 104/200 [03:29<03:05,  1.93s/it]Device set to use cuda\n",
      " 52%|\u2588\u2588\u2588\u2588\u2588\u258e    | 105/200 [03:31<02:58,  1.88s/it]Device set to use cuda\n",
      " 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 106/200 [03:33<02:46,  1.77s/it]Device set to use cuda\n",
      " 54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 107/200 [03:34<02:43,  1.76s/it]Device set to use cuda\n",
      " 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 108/200 [03:36<02:48,  1.83s/it]Device set to use cuda\n",
      " 55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 109/200 [03:38<02:52,  1.90s/it]Device set to use cuda\n",
      " 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 110/200 [03:40<02:54,  1.94s/it]Device set to use cuda\n",
      " 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 111/200 [03:42<02:48,  1.90s/it]Device set to use cuda\n",
      " 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 112/200 [03:44<02:54,  1.98s/it]Device set to use cuda\n",
      " 56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 113/200 [03:46<02:50,  1.96s/it]Device set to use cuda\n",
      " 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 114/200 [03:48<02:51,  1.99s/it]Device set to use cuda\n",
      " 57%|\u2588\u2588\u2588\u2588\u2588\u258a    | 115/200 [03:50<02:41,  1.90s/it]Device set to use cuda\n",
      " 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 116/200 [03:52<02:50,  2.03s/it]Device set to use cuda\n",
      " 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 117/200 [03:54<02:43,  1.98s/it]Device set to use cuda\n",
      " 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 118/200 [03:56<02:47,  2.05s/it]Device set to use cuda\n",
      " 60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 119/200 [03:59<02:48,  2.08s/it]Device set to use cuda\n",
      " 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 120/200 [04:00<02:35,  1.94s/it]Device set to use cuda\n",
      " 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 121/200 [04:02<02:34,  1.96s/it]Device set to use cuda\n",
      " 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 122/200 [04:05<02:45,  2.12s/it]Device set to use cuda\n",
      " 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 123/200 [04:07<02:51,  2.23s/it]Device set to use cuda\n",
      " 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 124/200 [04:09<02:33,  2.01s/it]Device set to use cuda\n",
      " 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 125/200 [04:11<02:30,  2.01s/it]Device set to use cuda\n",
      " 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 126/200 [04:12<02:19,  1.89s/it]Device set to use cuda\n",
      " 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 127/200 [04:14<02:15,  1.86s/it]Device set to use cuda\n",
      " 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 128/200 [04:16<02:20,  1.96s/it]Device set to use cuda\n",
      " 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 129/200 [04:18<02:16,  1.92s/it]Device set to use cuda\n",
      " 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 130/200 [04:20<02:13,  1.90s/it]Device set to use cuda\n",
      " 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 131/200 [04:22<02:04,  1.81s/it]Device set to use cuda\n",
      " 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 132/200 [04:23<02:04,  1.83s/it]Device set to use cuda\n",
      " 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 133/200 [04:26<02:09,  1.93s/it]Device set to use cuda\n",
      " 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 134/200 [04:28<02:08,  1.95s/it]Device set to use cuda\n",
      " 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 135/200 [04:29<02:03,  1.90s/it]Device set to use cuda\n",
      " 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 136/200 [04:31<02:01,  1.90s/it]Device set to use cuda\n",
      " 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 137/200 [04:33<02:00,  1.91s/it]Device set to use cuda\n",
      " 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 138/200 [04:35<01:55,  1.86s/it]Device set to use cuda\n",
      " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 139/200 [04:37<01:51,  1.82s/it]Device set to use cuda\n",
      " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 140/200 [04:38<01:43,  1.73s/it]Device set to use cuda\n",
      " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 141/200 [04:40<01:44,  1.77s/it]Device set to use cuda\n",
      " 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 142/200 [04:42<01:46,  1.84s/it]Device set to use cuda\n",
      " 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 143/200 [04:44<01:52,  1.98s/it]Device set to use cuda\n",
      " 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 144/200 [04:46<01:50,  1.97s/it]Device set to use cuda\n",
      " 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 145/200 [04:49<01:55,  2.10s/it]Device set to use cuda\n",
      " 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 146/200 [04:51<01:54,  2.12s/it]Device set to use cuda\n",
      " 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 147/200 [04:53<01:51,  2.10s/it]Device set to use cuda\n",
      " 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 148/200 [04:55<01:40,  1.93s/it]Device set to use cuda\n",
      " 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 149/200 [04:57<01:42,  2.02s/it]Device set to use cuda\n",
      " 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 150/200 [04:59<01:44,  2.09s/it]Device set to use cuda\n",
      " 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 151/200 [05:01<01:47,  2.20s/it]Device set to use cuda\n",
      " 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 152/200 [05:03<01:32,  1.94s/it]Device set to use cuda\n",
      " 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 153/200 [05:05<01:29,  1.91s/it]Device set to use cuda\n",
      " 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 154/200 [05:06<01:24,  1.84s/it]Device set to use cuda\n",
      " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 155/200 [05:08<01:22,  1.83s/it]Device set to use cuda\n",
      " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 156/200 [05:10<01:18,  1.77s/it]Device set to use cuda\n",
      " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 157/200 [05:11<01:08,  1.60s/it]Device set to use cuda\n",
      " 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 158/200 [05:13<01:09,  1.65s/it]Device set to use cuda\n",
      " 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 159/200 [05:15<01:15,  1.84s/it]Device set to use cuda\n",
      " 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 160/200 [05:17<01:10,  1.77s/it]Device set to use cuda\n",
      " 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 161/200 [05:18<01:03,  1.64s/it]Device set to use cuda\n",
      " 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 162/200 [05:20<01:04,  1.70s/it]Device set to use cuda\n",
      " 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 163/200 [05:22<01:08,  1.86s/it]Device set to use cuda\n",
      " 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 164/200 [05:24<01:04,  1.78s/it]Device set to use cuda\n",
      " 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 165/200 [05:25<01:03,  1.81s/it]Device set to use cuda\n",
      " 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 166/200 [05:28<01:10,  2.07s/it]Device set to use cuda\n",
      " 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 167/200 [05:30<01:10,  2.13s/it]Device set to use cuda\n",
      " 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 168/200 [05:32<01:06,  2.08s/it]Device set to use cuda\n",
      " 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 169/200 [05:34<01:02,  2.03s/it]Device set to use cuda\n",
      " 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 170/200 [05:37<01:05,  2.20s/it]Device set to use cuda\n",
      " 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 171/200 [05:38<00:55,  1.90s/it]Device set to use cuda\n",
      " 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 172/200 [05:40<00:51,  1.84s/it]Device set to use cuda\n",
      " 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 173/200 [05:42<00:53,  1.97s/it]Device set to use cuda\n",
      " 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 174/200 [05:44<00:50,  1.95s/it]Device set to use cuda\n",
      " 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 175/200 [05:46<00:45,  1.84s/it]Device set to use cuda\n",
      " 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 176/200 [05:47<00:43,  1.79s/it]Device set to use cuda\n",
      " 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 177/200 [05:49<00:40,  1.76s/it]Device set to use cuda\n",
      " 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 178/200 [05:51<00:41,  1.89s/it]Device set to use cuda\n",
      " 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 179/200 [05:54<00:43,  2.06s/it]Device set to use cuda\n",
      " 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 180/200 [05:55<00:39,  1.95s/it]Device set to use cuda\n",
      " 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 181/200 [05:57<00:38,  2.02s/it]Device set to use cuda\n",
      " 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 182/200 [05:59<00:34,  1.91s/it]Device set to use cuda\n",
      " 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 183/200 [06:01<00:33,  1.96s/it]Device set to use cuda\n",
      " 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 184/200 [06:03<00:32,  2.01s/it]Device set to use cuda\n",
      " 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 185/200 [06:06<00:31,  2.07s/it]Device set to use cuda\n",
      " 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 186/200 [06:08<00:28,  2.04s/it]Device set to use cuda\n",
      " 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 187/200 [06:10<00:27,  2.14s/it]Device set to use cuda\n",
      " 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 188/200 [06:12<00:26,  2.17s/it]Device set to use cuda\n",
      " 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 189/200 [06:14<00:22,  2.06s/it]Device set to use cuda\n",
      " 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 190/200 [06:16<00:19,  1.95s/it]Device set to use cuda\n",
      " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 191/200 [06:17<00:15,  1.70s/it]Device set to use cuda\n",
      " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 192/200 [06:18<00:12,  1.57s/it]Device set to use cuda\n",
      " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 193/200 [06:20<00:12,  1.76s/it]Device set to use cuda\n",
      " 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 194/200 [06:22<00:10,  1.76s/it]Device set to use cuda\n",
      " 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 195/200 [06:24<00:09,  1.92s/it]Device set to use cuda\n",
      " 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 196/200 [06:26<00:07,  1.98s/it]Device set to use cuda\n",
      " 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 197/200 [06:28<00:05,  1.85s/it]Device set to use cuda\n",
      " 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 198/200 [06:30<00:03,  1.95s/it]Device set to use cuda\n",
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 199/200 [06:32<00:01,  1.80s/it]Device set to use cuda\n",
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 200/200 [06:34<00:00,  1.97s/it]\n"
     ]
    }
   ],
   "source": [
    "#generate 200 titles having max length of 30 about cars using microsoft model\n",
    "MAX_LENGTH = 30\n",
    "TOPIC = \"cars\"\n",
    "NUM_TITLES = 200\n",
    "\n",
    "microsoft_titles = []\n",
    "for _ in tqdm(range(NUM_TITLES)):\n",
    "  chat = [\n",
    "      { \"role\": \"user\", \"content\": f\"You are a helpful ecommerce assistant.\\\n",
    "       Please generate an email title about {TOPIC} to enhance user engagement.\\\n",
    "        It should be short and concise. Do not generate any other comments.\" },\n",
    "  ]\n",
    "  pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "  )\n",
    "\n",
    "  generation_args = {\n",
    "    \"max_new_tokens\": MAX_LENGTH,\n",
    "    \"return_full_text\": False,\n",
    "\n",
    "    #probabilistic model\n",
    "    \"temperature\": 1,\n",
    "    \"do_sample\": True,\n",
    "  }\n",
    "  microsoft_titles.append(pipe(chat, **generation_args)[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#save the generated titles (repeated twice: microsoft_titles and microsoft_titles2)\n",
    "with open(\"../Data/microsoft_titles.json\", \"w\") as json_file:\n",
    "    json.dump(microsoft_titles, json_file)"
   ],
   "metadata": {
    "id": "9m7UVOdVQ9kp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735373872035,
     "user_tz": -180,
     "elapsed": 386,
     "user": {
      "displayName": "Egemen U\u011fur Dalg\u0131\u00e7",
      "userId": "05875523198878300823"
     }
    }
   },
   "execution_count": 4,
   "outputs": []
  }
 ]
}